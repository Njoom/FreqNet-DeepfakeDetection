{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Njoom/FreqNet-DeepfakeDetection/blob/main/PaperImplemenation_Frequency_Aware_Deepfake_Detection_Improving_Generalizability_through_Frequency_Space_Domain_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tb5bXllk5ruQ",
        "outputId": "8fbb48e4-6e44-400d-f4a1-62a5176df46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FreqNet-DeepfakeDetection'...\n",
            "remote: Enumerating objects: 204, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (197/197), done.\u001b[K\n",
            "remote: Total 204 (delta 107), reused 31 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (204/204), 8.66 MiB | 13.92 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Njoom/FreqNet-DeepfakeDetection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "imKOiWQO52Gp",
        "outputId": "d86d5646-bff4-42a6-9cf1-bb1f53dcf849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#import data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WGNU8vGG6HM4",
        "outputId": "660cdb43-4820-43a3-f1ae-704e368f43da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FreqNet-DeepfakeDetection\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.20.1+cu124)\n",
            "Collecting gdown==4.7.1 (from -r requirements.txt (line 8))\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting tensorboardX (from -r requirements.txt (line 9))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown==4.7.1->-r requirements.txt (line 8)) (4.13.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (4.25.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown==4.7.1->-r requirements.txt (line 8)) (2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.2.0->-r requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 8)) (1.7.1)\n",
            "Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, gdown\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 5.2.0\n",
            "    Uninstalling gdown-5.2.0:\n",
            "      Successfully uninstalled gdown-5.2.0\n",
            "Successfully installed gdown-4.7.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FreqNet-DeepfakeDetection\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugXwVTDs8KvZ",
        "outputId": "9ee112b6-3480-43e7-e562-8c740c5bb75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                     arch: res50                         \n",
            "               batch_size: 64                            \n",
            "                    beta1: 0.9                           \n",
            "                blur_prob: 0                             \n",
            "                 blur_sig: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                class_bal: False                         \n",
            "                  classes: 0_real,1_fake                 \n",
            "           continue_train: False                         \n",
            "                 cropSize: 224                           \n",
            "                 data_aug: False                         \n",
            "                 dataroot: /content/drive/MyDrive/CelebA_Test_FreqNetPaper\n",
            "                delr_freq: 20                            \n",
            "          earlystop_epoch: 15                            \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                  isTrain: True                          \t[default: None]\n",
            "               jpg_method: cv2                           \n",
            "                 jpg_prob: 0                             \n",
            "                 jpg_qual: 75                            \n",
            "               last_epoch: -1                            \n",
            "                 loadSize: 256                           \n",
            "                loss_freq: 400                           \n",
            "                       lr: 0.0001                        \n",
            "                     mode: binary                        \n",
            "                     name: experiment_name2025_02_15_19_16_34\t[default: experiment_name]\n",
            "                new_optim: False                         \n",
            "                    niter: 10                            \n",
            "                  no_flip: False                         \n",
            "              num_threads: 8                             \n",
            "                    optim: adam                          \n",
            "           resize_or_crop: scale_and_crop                \n",
            "                rz_interp: bilinear                      \n",
            "          save_epoch_freq: 20                            \n",
            "         save_latest_freq: 200                           \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "              train_split: train                         \n",
            "                val_split: val                           \n",
            "----------------- End -------------------\n",
            "train.py\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "==================== requires_grad Ture weight1\n",
            "==================== requires_grad Ture bias1\n",
            "==================== requires_grad Ture weight2\n",
            "==================== requires_grad Ture bias2\n",
            "==================== requires_grad Ture weight3\n",
            "==================== requires_grad Ture bias3\n",
            "==================== requires_grad Ture weight4\n",
            "==================== requires_grad Ture bias4\n",
            "==================== requires_grad Ture realconv1.weight\n",
            "==================== requires_grad Ture imagconv1.weight\n",
            "==================== requires_grad Ture realconv2.weight\n",
            "==================== requires_grad Ture imagconv2.weight\n",
            "==================== requires_grad Ture realconv3.weight\n",
            "==================== requires_grad Ture imagconv3.weight\n",
            "==================== requires_grad Ture realconv4.weight\n",
            "==================== requires_grad Ture imagconv4.weight\n",
            "==================== requires_grad Ture layer1.0.conv1.weight\n",
            "==================== requires_grad Ture layer1.0.bn1.weight\n",
            "==================== requires_grad Ture layer1.0.bn1.bias\n",
            "==================== requires_grad Ture layer1.0.conv2.weight\n",
            "==================== requires_grad Ture layer1.0.bn2.weight\n",
            "==================== requires_grad Ture layer1.0.bn2.bias\n",
            "==================== requires_grad Ture layer1.0.conv3.weight\n",
            "==================== requires_grad Ture layer1.0.bn3.weight\n",
            "==================== requires_grad Ture layer1.0.bn3.bias\n",
            "==================== requires_grad Ture layer1.0.downsample.0.weight\n",
            "==================== requires_grad Ture layer1.0.downsample.1.weight\n",
            "==================== requires_grad Ture layer1.0.downsample.1.bias\n",
            "==================== requires_grad Ture layer1.1.conv1.weight\n",
            "==================== requires_grad Ture layer1.1.bn1.weight\n",
            "==================== requires_grad Ture layer1.1.bn1.bias\n",
            "==================== requires_grad Ture layer1.1.conv2.weight\n",
            "==================== requires_grad Ture layer1.1.bn2.weight\n",
            "==================== requires_grad Ture layer1.1.bn2.bias\n",
            "==================== requires_grad Ture layer1.1.conv3.weight\n",
            "==================== requires_grad Ture layer1.1.bn3.weight\n",
            "==================== requires_grad Ture layer1.1.bn3.bias\n",
            "==================== requires_grad Ture layer1.2.conv1.weight\n",
            "==================== requires_grad Ture layer1.2.bn1.weight\n",
            "==================== requires_grad Ture layer1.2.bn1.bias\n",
            "==================== requires_grad Ture layer1.2.conv2.weight\n",
            "==================== requires_grad Ture layer1.2.bn2.weight\n",
            "==================== requires_grad Ture layer1.2.bn2.bias\n",
            "==================== requires_grad Ture layer1.2.conv3.weight\n",
            "==================== requires_grad Ture layer1.2.bn3.weight\n",
            "==================== requires_grad Ture layer1.2.bn3.bias\n",
            "==================== requires_grad Ture layer2.0.conv1.weight\n",
            "==================== requires_grad Ture layer2.0.bn1.weight\n",
            "==================== requires_grad Ture layer2.0.bn1.bias\n",
            "==================== requires_grad Ture layer2.0.conv2.weight\n",
            "==================== requires_grad Ture layer2.0.bn2.weight\n",
            "==================== requires_grad Ture layer2.0.bn2.bias\n",
            "==================== requires_grad Ture layer2.0.conv3.weight\n",
            "==================== requires_grad Ture layer2.0.bn3.weight\n",
            "==================== requires_grad Ture layer2.0.bn3.bias\n",
            "==================== requires_grad Ture layer2.0.downsample.0.weight\n",
            "==================== requires_grad Ture layer2.0.downsample.1.weight\n",
            "==================== requires_grad Ture layer2.0.downsample.1.bias\n",
            "==================== requires_grad Ture layer2.1.conv1.weight\n",
            "==================== requires_grad Ture layer2.1.bn1.weight\n",
            "==================== requires_grad Ture layer2.1.bn1.bias\n",
            "==================== requires_grad Ture layer2.1.conv2.weight\n",
            "==================== requires_grad Ture layer2.1.bn2.weight\n",
            "==================== requires_grad Ture layer2.1.bn2.bias\n",
            "==================== requires_grad Ture layer2.1.conv3.weight\n",
            "==================== requires_grad Ture layer2.1.bn3.weight\n",
            "==================== requires_grad Ture layer2.1.bn3.bias\n",
            "==================== requires_grad Ture layer2.2.conv1.weight\n",
            "==================== requires_grad Ture layer2.2.bn1.weight\n",
            "==================== requires_grad Ture layer2.2.bn1.bias\n",
            "==================== requires_grad Ture layer2.2.conv2.weight\n",
            "==================== requires_grad Ture layer2.2.bn2.weight\n",
            "==================== requires_grad Ture layer2.2.bn2.bias\n",
            "==================== requires_grad Ture layer2.2.conv3.weight\n",
            "==================== requires_grad Ture layer2.2.bn3.weight\n",
            "==================== requires_grad Ture layer2.2.bn3.bias\n",
            "==================== requires_grad Ture layer2.3.conv1.weight\n",
            "==================== requires_grad Ture layer2.3.bn1.weight\n",
            "==================== requires_grad Ture layer2.3.bn1.bias\n",
            "==================== requires_grad Ture layer2.3.conv2.weight\n",
            "==================== requires_grad Ture layer2.3.bn2.weight\n",
            "==================== requires_grad Ture layer2.3.bn2.bias\n",
            "==================== requires_grad Ture layer2.3.conv3.weight\n",
            "==================== requires_grad Ture layer2.3.bn3.weight\n",
            "==================== requires_grad Ture layer2.3.bn3.bias\n",
            "==================== requires_grad Ture fc1.weight\n",
            "==================== requires_grad Ture fc1.bias\n",
            "\n",
            "cwd: /content/FreqNet-DeepfakeDetection\n",
            "(Val @ epoch 0) acc: 0.3333333333333333; ap: 0.575\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 1) acc: 0.3333333333333333; ap: 0.525\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 2) acc: 0.3333333333333333; ap: 0.43465909090909094\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 3) acc: 0.3333333333333333; ap: 0.6013257575757576\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 4) acc: 0.3333333333333333; ap: 0.59375\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 5) acc: 0.3333333333333333; ap: 0.48971861471861466\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 6) acc: 0.3333333333333333; ap: 0.5595238095238095\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 7) acc: 0.3333333333333333; ap: 0.3506944444444444\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 8) acc: 0.3333333333333333; ap: 0.38075396825396823\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(Val @ epoch 9) acc: 0.3333333333333333; ap: 0.3875\n",
            "*************************\n",
            "2025_02_15_19_16_53\n",
            "Class directory: /content/drive/MyDrive/CelebA_Test_FreqNetPaper/test/0_real\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(0 0_real    ) acc: 33.3; ap: 38.1\n",
            "Class directory: /content/drive/MyDrive/CelebA_Test_FreqNetPaper/test/1_fake\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(1 1_fake    ) acc: 33.3; ap: 38.1\n",
            "(2 Mean      ) acc: 33.3; ap: 38.1\n",
            "*************************\n",
            "2025_02_15_19_16_55\n",
            "Saving model ./checkpoints/experiment_name2025_02_15_19_16_34/model_epoch_last.pth\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E6P4tRajZ17",
        "outputId": "9e0a7812-d9cf-4fc2-8451-6cd1272d399d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model_path ./checkpoints/experiment_name2025_02_15_19_16_34/model_epoch_last.pth\n",
            "/content/FreqNet-DeepfakeDetection/test.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(opt.model_path, map_location='cpu'), strict=True)\n",
            "2025_02_15_19_17_15\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(0 0_real      ) acc: 33.3; ap: 38.1\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "(1 1_fake      ) acc: 33.3; ap: 38.1\n",
            "(2 Mean      ) acc: 33.3; ap: 38.1\n",
            "*************************\n"
          ]
        }
      ],
      "source": [
        "!python test.py --model_path ./checkpoints/experiment_name2025_02_15_19_16_34/model_epoch_last.pth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOx0Os6wbYjA0lkg4vlCpvr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}